{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescription-validity",
   "metadata": {},
   "source": [
    "# Cours Programmation Dynamique\n",
    "### Source     :\n",
    "### Adaptation : Fabrice Mulotti\n",
    "v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a95e167-7e49-4413-900d-20cde3556719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "\n",
    "from lib.envs.windy_gridworld import WindyGridworldEnv\n",
    "\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a848409-264f-4dad-ae27-82897e01c53e",
   "metadata": {},
   "source": [
    "### Déclaration env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake8x8-v1',is_slippery = True)\n",
    "# env = gym.make('FrozenLake-v1',is_slippery=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b54f9-76ad-46c0-ba8d-338732c092c3",
   "metadata": {},
   "source": [
    "### Quelques caractéristiques de notre env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb5177-5b76-4da0-92fd-100b3033b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-effort",
   "metadata": {},
   "source": [
    "env.P[s] nous permet de déterminer en fonction de l'état s et de l'action a:\n",
    "prob , s' , r , final ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24618377-04aa-425c-ae7c-1f1a826aadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.P[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8ca73-6df5-4528-8865-c50101c541d2",
   "metadata": {},
   "source": [
    "-> Exemple pour l'état 0 et l'action 0 et le premier état s' dans la liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.P[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-strand",
   "metadata": {},
   "source": [
    "![title](static/value_iteration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recherche de v*\n",
    "def value_iteration(env,theta,max_iter,gamma):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    deltaT = []\n",
    "\n",
    "    ## Votre code : initialiser le tableau fonction valeur\n",
    "    for k in range(max_iter):\n",
    "        save_fvalue=np.copy(fvalue) # double tableau\n",
    "        for s in range(env.observation_space.n):  \n",
    "            max_Qa = -100\n",
    "            for a in range(env.action_space.n):\n",
    "                q=0\n",
    "                for p,s_,r,done in env.P[s][a]:\n",
    "                    # Votre code : calculer pour chaque s,a,s' l'espérance de récompense\n",
    "                # Votre code : ne conserver que l'espérance maximum\n",
    "\n",
    "            # votre code : mettre à jour le tableau avec la récompense max pour l'état s\n",
    "        # VOTRE CODE : Calculer delta entre le tableau fvalue et save_fvalue pour mesurer l'écart\n",
    "        \n",
    "        if int(k/100)==k/100:\n",
    "            ax.plot(deltaT)\n",
    "            fig.canvas.draw()\n",
    "\n",
    "        # condition de sortie ?\n",
    "        if (delta <= theta):\n",
    "            break\n",
    "    return(k,fvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563798d-9c20-4d44-9309-bd1ee80753d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "k,fv=value_iteration(env=env,theta=1e-20,max_iter=10000,gamma=0.8)\n",
    "print(k,\" itérations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff3a9b-671b-40fc-9bb7-3343e729fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17f282-690a-43e8-9ba1-73d6a87e74a3",
   "metadata": {},
   "source": [
    "*** \n",
    "# Phase 2 : déterminer la meilleur politique en fonction de v*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1903bb-30b9-46dd-bb64-1199413e9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination de la meilleur politique pi*\n",
    "def best_policy(env,fvalue,gamma):\n",
    "    # votre code : initiliser à 0 la politique : policy\n",
    "    for s in range(env.observation_space.n):\n",
    "        Q = []\n",
    "        for a in range(env.action_space.n):\n",
    "            q=0\n",
    "            for p,s_,r,done in env.P[s][a]:\n",
    "                # votre code : pour chaque s,a,s' calculer l'expérance de gain\n",
    "            # votre code et l'ajouter à Q (ajout dans la liste)\n",
    "        policy[s]=np.argmax(Q)\n",
    "    return(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92946aba-e6b5-4ab2-b236-42f2e57ef85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=best_policy(env,fv,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5aacb-a2ab-4158-989f-dd45286cb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"iteration_valeur_best_policy\",policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed76a3-593e-4e99-b7c7-60214818152b",
   "metadata": {},
   "source": [
    "# Testons l'environnement\n",
    "\n",
    "0: LEFT <br>\n",
    "1: DOWN<br>\n",
    "2: RIGHT<br>\n",
    "3: UP<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c13d54-1764-4d9c-acd9-1a00ece73140",
   "metadata": {},
   "outputs": [],
   "source": [
    "curpos=env.reset()\n",
    "env.render()\n",
    "print(policy)\n",
    "done=False\n",
    "print(\"Start\")\n",
    "while done == False:\n",
    "    back=env.step(int(policy[curpos]))\n",
    "    # print(\"Curpos \",curpos,\", Policy \",policy[curpos],back)\n",
    "    curpos=back[0]\n",
    "    done=back[2]\n",
    "    # env.render()\n",
    "    # time.sleep(1)\n",
    "print(\"Done \",back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e3560-c177-43c5-9347-6aa07147e0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laboRL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
